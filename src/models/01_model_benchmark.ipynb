{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdec8155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.join(os.getcwd(), '..', 'features')\n",
    "sys.path.append(module_path)\n",
    "from utils import preprocess_sales\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from darts import TimeSeries\n",
    "from darts.models import (\n",
    "    ARIMA, AutoARIMA, \n",
    "    ExponentialSmoothing,\n",
    "    Prophet,\n",
    "    RandomForest,\n",
    "    LightGBMModel,\n",
    "    XGBModel,\n",
    "    RNNModel,\n",
    "    TCNModel,\n",
    "    NHiTSModel\n",
    ")\n",
    "from darts.metrics import mape, rmse, mae\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4002f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>...</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id    d  sales        date  wm_yr_wk  ... month  year  event_name_1  \\\n",
       "0       CA  d_1      0  2011-01-29     11101  ...     1  2011           NaN   \n",
       "1       CA  d_1      0  2011-01-29     11101  ...     1  2011           NaN   \n",
       "2       CA  d_1      0  2011-01-29     11101  ...     1  2011           NaN   \n",
       "3       CA  d_1      0  2011-01-29     11101  ...     1  2011           NaN   \n",
       "4       CA  d_1      0  2011-01-29     11101  ...     1  2011           NaN   \n",
       "\n",
       "   event_type_1 event_name_2 event_type_2 snap_CA snap_TX  snap_WI  sell_price  \n",
       "0           NaN          NaN          NaN       0       0        0         NaN  \n",
       "1           NaN          NaN          NaN       0       0        0         NaN  \n",
       "2           NaN          NaN          NaN       0       0        0         NaN  \n",
       "3           NaN          NaN          NaN       0       0        0         NaN  \n",
       "4           NaN          NaN          NaN       0       0        0         NaN  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_calendar_prices = (\n",
    "    pd.read_csv(\"../../Data/sales_train_validation.csv\")\n",
    "    .melt(\n",
    "            id_vars=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],\n",
    "            var_name='d',\n",
    "            value_name='sales'\n",
    "    )\n",
    "    .merge(pd.read_csv(\"../../Data/calendar.csv\"), on='d', how='left')\n",
    "    .merge(pd.read_csv(\"../../Data/sell_prices.csv\"), on=['wm_yr_wk', 'item_id', 'store_id'], how='left')\n",
    ")\n",
    "sales_calendar_prices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95ed1c2",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83507c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Load and Prepare Data\n",
    "# ============================================\n",
    "def prepare_data(df, id_col='id', date_col='date', target_col='sales'):\n",
    "    \"\"\"\n",
    "    Prepare data for Darts forecasting\n",
    "    \"\"\"\n",
    "    # Categorical features to encode\n",
    "    cat_features = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', \n",
    "                    'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    df_encoded = df.copy()\n",
    "    for col in cat_features:\n",
    "        if col in df_encoded.columns:\n",
    "            df_encoded[col] = pd.Categorical(df_encoded[col]).codes\n",
    "    \n",
    "    return df_encoded\n",
    "\n",
    "def create_timeseries(df, id_value, date_col='date', target_col='sales'):\n",
    "    \"\"\"\n",
    "    Create Darts TimeSeries for a specific item-store combination\n",
    "    \"\"\"\n",
    "    # Filter for specific id\n",
    "    df_filtered = df[df['id'] == id_value].sort_values(date_col).reset_index(drop=True)\n",
    "    \n",
    "    # Create target series\n",
    "    target = TimeSeries.from_dataframe(\n",
    "        df_filtered, \n",
    "        time_col=date_col, \n",
    "        value_cols=target_col,\n",
    "        fill_missing_dates=True,\n",
    "        freq='D'\n",
    "    )\n",
    "    \n",
    "    # Create covariates (explanatory variables)\n",
    "    covariate_cols = ['wday', 'month', 'year', 'item_id', 'dept_id', 'cat_id', \n",
    "                      'store_id', 'state_id', 'event_name_1', 'event_type_1', \n",
    "                      'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI']\n",
    "    \n",
    "    available_cols = [col for col in covariate_cols if col in df_filtered.columns]\n",
    "    \n",
    "    if available_cols:\n",
    "        covariates = TimeSeries.from_dataframe(\n",
    "            df_filtered,\n",
    "            time_col=date_col,\n",
    "            value_cols=available_cols,\n",
    "            fill_missing_dates=True,\n",
    "            freq='D'\n",
    "        )\n",
    "    else:\n",
    "        covariates = None\n",
    "    \n",
    "    return target, covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5432bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsse(train, actual, forecast):\n",
    "    if hasattr(train, 'values'):\n",
    "        train = train.values()\n",
    "    if hasattr(actual, 'values'):\n",
    "        actual = actual.values()\n",
    "    if hasattr(forecast, 'values'):\n",
    "        forecast = forecast.values()\n",
    "    \n",
    "    train = np.array(train).flatten()\n",
    "    actual = np.array(actual).flatten()\n",
    "    forecast = np.array(forecast).flatten()\n",
    "    \n",
    "    mse_forecast = np.mean((actual - forecast)**2)\n",
    "    scale = np.mean(np.diff(train)**2)\n",
    "    \n",
    "    if scale == 0 or scale < 1e-10:\n",
    "        return np.inf\n",
    "    \n",
    "    return np.sqrt(mse_forecast / scale)\n",
    "\n",
    "\n",
    "def safe_metrics(train, actual, predicted):\n",
    "    r = rmsse(train, actual, predicted)\n",
    "    return {\n",
    "        'RMSE': rmse(actual, predicted),  \n",
    "        'MAE': mae(actual, predicted),   \n",
    "        'RMSSE': r,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e972c8",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be5397cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Configuration\n",
    "# ============================================\n",
    "FORECAST_HORIZON = 60  \n",
    "TRAIN_TEST_SPLIT = 0.95  \n",
    "\n",
    "print(\"Preparing data...\")\n",
    "df_prepared = prepare_data(sales_calendar_prices)\n",
    "unique_ids = df_prepared['id'].unique()\n",
    "del sales_calendar_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4be848",
   "metadata": {},
   "source": [
    "### ARIMA, Exponential Smoothing and Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0367ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]16:30:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:30:44 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 1/500 [00:08<1:11:58,  8.65s/it]16:30:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:30:50 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 2/500 [00:13<53:35,  6.46s/it]  16:30:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:30:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  1%|          | 3/500 [00:17<44:57,  5.43s/it]16:31:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:31:01 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  1%|          | 4/500 [00:25<51:28,  6.23s/it]16:31:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:31:06 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  1%|          | 5/500 [00:29<44:53,  5.44s/it]16:31:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:31:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  1%|          | 6/500 [00:38<55:50,  6.78s/it]16:31:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:31:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:31:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:31:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  2%|▏         | 8/500 [00:47<44:46,  5.46s/it]16:31:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:31:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  2%|▏         | 9/500 [00:52<42:54,  5.24s/it]16:31:33 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:31:33 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  2%|▏         | 10/500 [00:56<40:27,  4.96s/it]16:31:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:31:40 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:31:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "  2%|▏         | 11/500 [01:04<46:24,  5.69s/it]16:31:44 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  2%|▏         | 12/500 [01:07<40:22,  4.96s/it]16:31:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:31:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:31:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "  3%|▎         | 13/500 [01:15<48:45,  6.01s/it]16:31:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:31:56 - cmdstanpy - ERROR - Chain [1] error: error during processing Operation not permitted\n",
      "Optimization terminated abnormally. Falling back to Newton.\n",
      "16:31:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:31:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:31:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  3%|▎         | 14/500 [01:21<47:33,  5.87s/it]16:32:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  3%|▎         | 15/500 [01:27<48:10,  5.96s/it]16:32:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:32:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:32:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:32:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  3%|▎         | 17/500 [01:36<40:02,  4.98s/it]16:32:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:32:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  4%|▎         | 18/500 [01:45<50:43,  6.31s/it]16:32:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:32:26 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  4%|▍         | 19/500 [01:50<47:17,  5.90s/it]16:32:33 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:32:33 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  4%|▍         | 20/500 [01:56<47:47,  5.97s/it]16:32:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:32:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:32:46 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:32:46 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  4%|▍         | 22/500 [02:13<53:27,  6.71s/it]  16:32:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:32:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  5%|▍         | 23/500 [02:16<46:16,  5.82s/it]16:32:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:32:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  5%|▍         | 24/500 [02:20<41:33,  5.24s/it]16:33:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:33:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  5%|▌         | 25/500 [02:29<49:15,  6.22s/it]16:33:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:33:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  5%|▌         | 26/500 [02:35<48:20,  6.12s/it]16:33:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:33:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:33:20 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:33:20 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  6%|▌         | 28/500 [02:47<46:26,  5.90s/it]16:33:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:33:31 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  6%|▌         | 29/500 [02:55<50:19,  6.41s/it]16:33:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:33:36 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  6%|▌         | 30/500 [02:59<45:34,  5.82s/it]16:33:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:33:46 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  6%|▌         | 31/500 [03:10<57:26,  7.35s/it]16:33:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:33:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  6%|▋         | 32/500 [03:15<52:25,  6.72s/it]16:34:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:34:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  7%|▋         | 33/500 [03:27<1:03:20,  8.14s/it]16:34:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:34:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:34:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  7%|▋         | 34/500 [03:30<52:42,  6.79s/it]  16:34:10 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  7%|▋         | 35/500 [03:34<44:49,  5.78s/it]16:34:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:34:17 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  7%|▋         | 36/500 [03:40<45:19,  5.86s/it]16:34:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:34:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:34:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:34:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:34:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:34:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  8%|▊         | 39/500 [03:57<39:56,  5.20s/it]16:34:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:34:37 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  8%|▊         | 40/500 [04:01<37:07,  4.84s/it]16:34:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:34:43 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  8%|▊         | 41/500 [04:06<37:45,  4.94s/it]16:34:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:34:49 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  8%|▊         | 42/500 [04:14<43:52,  5.75s/it]16:34:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:34:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:34:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "  9%|▊         | 43/500 [04:18<39:46,  5.22s/it]16:34:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  9%|▉         | 44/500 [04:21<35:32,  4.68s/it]16:35:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:35:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  9%|▉         | 45/500 [04:29<42:53,  5.66s/it]16:35:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:35:13 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  9%|▉         | 46/500 [04:36<47:07,  6.23s/it]16:35:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:35:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:35:17 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:35:17 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:35:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "  9%|▉         | 47/500 [04:41<42:05,  5.57s/it]16:35:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 10%|▉         | 49/500 [04:47<33:16,  4.43s/it]16:35:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:35:32 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:35:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:35:32 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 10%|█         | 51/500 [04:59<37:02,  4.95s/it]16:35:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:35:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:35:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:35:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 10%|█         | 52/500 [05:10<51:43,  6.93s/it]16:35:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      " 11%|█         | 53/500 [05:14<43:54,  5.89s/it]16:35:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 11%|█         | 54/500 [05:17<38:38,  5.20s/it]16:35:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:35:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 11%|█         | 55/500 [05:21<35:08,  4.74s/it]16:36:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:36:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 11%|█         | 56/500 [05:28<39:00,  5.27s/it]16:36:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:36:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 11%|█▏        | 57/500 [05:32<36:29,  4.94s/it]16:36:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:36:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:36:16 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 12%|█▏        | 58/500 [05:40<42:33,  5.78s/it]16:36:20 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:36:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      " 12%|█▏        | 59/500 [05:43<37:06,  5.05s/it]16:36:23 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 12%|█▏        | 60/500 [05:46<33:40,  4.59s/it]16:36:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:36:30 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 12%|█▏        | 61/500 [05:54<39:01,  5.33s/it]16:36:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:36:34 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 12%|█▏        | 62/500 [05:58<37:22,  5.12s/it]16:36:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:36:39 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 13%|█▎        | 63/500 [06:02<35:30,  4.88s/it]16:36:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:36:50 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 13%|█▎        | 64/500 [06:14<49:52,  6.86s/it]16:36:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:36:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:36:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:36:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 13%|█▎        | 66/500 [06:23<39:31,  5.46s/it]16:37:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:37:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 13%|█▎        | 67/500 [06:27<36:54,  5.11s/it]16:37:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:37:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 14%|█▎        | 68/500 [06:31<35:26,  4.92s/it]16:37:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:37:15 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 14%|█▍        | 69/500 [06:38<38:47,  5.40s/it]16:37:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:37:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:37:19 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 14%|█▍        | 70/500 [06:42<36:48,  5.14s/it]16:37:22 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 14%|█▍        | 71/500 [06:46<32:37,  4.56s/it]16:37:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:37:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:37:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:37:28 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 15%|█▍        | 73/500 [06:54<31:00,  4.36s/it]16:37:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:37:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:37:37 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:37:37 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 15%|█▌        | 75/500 [07:05<32:43,  4.62s/it]16:37:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:37:46 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 15%|█▌        | 76/500 [07:09<33:02,  4.68s/it]16:37:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:37:51 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:37:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      " 15%|█▌        | 77/500 [07:14<32:38,  4.63s/it]16:37:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 16%|█▌        | 78/500 [07:17<29:51,  4.25s/it]16:38:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:38:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:38:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:38:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 16%|█▌        | 80/500 [07:29<33:09,  4.74s/it]16:38:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:38:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:38:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      " 16%|█▌        | 81/500 [07:38<43:26,  6.22s/it]16:38:18 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 16%|█▋        | 82/500 [07:42<37:59,  5.45s/it]16:38:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:38:23 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 17%|█▋        | 83/500 [07:47<36:19,  5.23s/it]16:38:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:38:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 17%|█▋        | 84/500 [07:50<32:55,  4.75s/it]16:38:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:38:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:38:37 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:38:37 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 17%|█▋        | 86/500 [08:04<37:16,  5.40s/it]16:38:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:38:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:38:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:38:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 18%|█▊        | 88/500 [08:13<34:09,  4.97s/it]16:38:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:38:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:38:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 18%|█▊        | 89/500 [08:21<39:30,  5.77s/it]16:39:01 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 18%|█▊        | 90/500 [08:24<34:39,  5.07s/it]16:39:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:39:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:39:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      " 18%|█▊        | 91/500 [08:36<47:47,  7.01s/it]16:39:16 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 18%|█▊        | 92/500 [08:40<41:16,  6.07s/it]16:39:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:39:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 19%|█▊        | 93/500 [08:44<37:42,  5.56s/it]16:39:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:39:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 19%|█▉        | 94/500 [08:48<33:55,  5.01s/it]16:39:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:39:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 19%|█▉        | 95/500 [08:53<33:06,  4.91s/it]16:39:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:39:35 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 19%|█▉        | 96/500 [08:58<34:10,  5.07s/it]16:39:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:39:39 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 19%|█▉        | 97/500 [09:03<33:12,  4.94s/it]16:39:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:39:44 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:39:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      " 20%|█▉        | 98/500 [09:08<33:03,  4.93s/it]16:39:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 20%|█▉        | 99/500 [09:11<30:08,  4.51s/it]16:39:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:39:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 20%|██        | 100/500 [09:17<32:17,  4.84s/it]16:39:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:39:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 20%|██        | 101/500 [09:21<31:58,  4.81s/it]16:40:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:40:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 20%|██        | 102/500 [09:25<29:24,  4.43s/it]16:40:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:40:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 21%|██        | 103/500 [09:32<34:36,  5.23s/it]16:40:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:40:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:40:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:40:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 21%|██        | 105/500 [09:40<29:56,  4.55s/it]16:40:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:40:22 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 21%|██        | 106/500 [09:45<31:12,  4.75s/it]16:40:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:40:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:40:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:40:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 22%|██▏       | 108/500 [09:55<30:52,  4.73s/it]16:40:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:40:40 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 22%|██▏       | 109/500 [10:03<37:12,  5.71s/it]16:40:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:40:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 22%|██▏       | 110/500 [10:11<40:00,  6.15s/it]16:40:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:40:51 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 22%|██▏       | 111/500 [10:14<34:42,  5.35s/it]16:40:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:40:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 22%|██▏       | 112/500 [10:23<41:19,  6.39s/it]16:41:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:41:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 23%|██▎       | 113/500 [10:27<35:51,  5.56s/it]16:41:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:41:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 23%|██▎       | 114/500 [10:35<41:55,  6.52s/it]16:41:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:41:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:41:20 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:41:20 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 23%|██▎       | 116/500 [10:47<37:46,  5.90s/it]16:41:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:41:32 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:41:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      " 23%|██▎       | 117/500 [10:55<42:23,  6.64s/it]16:41:35 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 24%|██▎       | 118/500 [10:58<35:46,  5.62s/it]16:41:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:41:46 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 24%|██▍       | 119/500 [11:10<46:43,  7.36s/it]16:41:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:41:50 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 24%|██▍       | 120/500 [11:14<40:56,  6.46s/it]16:41:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:41:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 24%|██▍       | 121/500 [11:18<36:03,  5.71s/it]16:42:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:42:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 24%|██▍       | 122/500 [11:28<44:11,  7.01s/it]16:42:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:42:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 25%|██▍       | 123/500 [11:32<37:50,  6.02s/it]16:42:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:42:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 25%|██▍       | 124/500 [11:38<37:27,  5.98s/it]16:42:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:42:23 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 25%|██▌       | 125/500 [11:46<42:16,  6.76s/it]16:42:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:42:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 25%|██▌       | 126/500 [11:52<39:33,  6.34s/it]16:42:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:42:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:42:35 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:42:35 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 26%|██▌       | 128/500 [12:01<33:42,  5.44s/it]16:42:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:42:42 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 26%|██▌       | 129/500 [12:06<32:03,  5.18s/it]16:42:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:42:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 26%|██▌       | 130/500 [12:11<31:01,  5.03s/it]16:42:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:42:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 26%|██▌       | 131/500 [12:15<29:19,  4.77s/it]16:42:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:42:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 26%|██▋       | 132/500 [12:21<31:55,  5.21s/it]16:43:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:43:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 27%|██▋       | 133/500 [12:29<36:00,  5.89s/it]16:43:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:43:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 27%|██▋       | 134/500 [12:33<33:11,  5.44s/it]16:43:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:43:15 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 27%|██▋       | 135/500 [12:39<33:21,  5.48s/it]16:43:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:43:19 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 27%|██▋       | 136/500 [12:42<29:37,  4.88s/it]16:43:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:43:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 27%|██▋       | 137/500 [12:48<31:41,  5.24s/it]16:43:33 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:43:33 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:43:33 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:43:33 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 28%|██▊       | 138/500 [12:56<36:49,  6.10s/it]16:43:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      " 28%|██▊       | 139/500 [13:00<31:53,  5.30s/it]16:43:40 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 28%|██▊       | 140/500 [13:04<30:03,  5.01s/it]16:43:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:43:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:43:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 28%|██▊       | 141/500 [13:11<33:52,  5.66s/it]16:43:51 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:43:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:43:51 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 29%|██▊       | 143/500 [13:18<26:48,  4.51s/it]16:44:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:44:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 29%|██▉       | 144/500 [13:25<31:43,  5.35s/it]16:44:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:44:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 29%|██▉       | 145/500 [13:30<31:06,  5.26s/it]16:44:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:44:10 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 29%|██▉       | 146/500 [13:34<27:53,  4.73s/it]16:44:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:44:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 29%|██▉       | 147/500 [13:44<38:12,  6.50s/it]16:44:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:44:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 30%|██▉       | 148/500 [13:48<33:19,  5.68s/it]16:44:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:44:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 30%|██▉       | 149/500 [13:53<30:58,  5.30s/it]16:44:33 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:44:33 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 30%|███       | 150/500 [13:57<29:14,  5.01s/it]16:44:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:44:38 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 30%|███       | 151/500 [14:01<28:21,  4.87s/it]16:44:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:44:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 30%|███       | 152/500 [14:11<36:07,  6.23s/it]16:44:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:44:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 31%|███       | 153/500 [14:17<36:22,  6.29s/it]16:44:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:44:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:44:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:44:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 31%|███       | 155/500 [14:25<28:42,  4.99s/it]16:45:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:45:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 31%|███       | 156/500 [14:33<33:23,  5.82s/it]16:45:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:45:13 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 31%|███▏      | 157/500 [14:36<29:45,  5.20s/it]16:45:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:45:19 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:45:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:45:19 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 32%|███▏      | 159/500 [14:47<28:37,  5.04s/it]16:45:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:45:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 32%|███▏      | 160/500 [14:53<30:00,  5.30s/it]16:45:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:45:34 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 32%|███▏      | 161/500 [14:58<29:23,  5.20s/it]16:45:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:45:40 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 32%|███▏      | 162/500 [15:03<29:59,  5.33s/it]16:45:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:45:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 33%|███▎      | 163/500 [15:10<32:27,  5.78s/it]16:45:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:45:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:45:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:45:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 33%|███▎      | 165/500 [15:20<29:35,  5.30s/it]16:46:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:46:06 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 33%|███▎      | 166/500 [15:29<35:20,  6.35s/it]16:46:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:46:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 33%|███▎      | 167/500 [15:33<30:36,  5.51s/it]16:46:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:46:15 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 34%|███▎      | 168/500 [15:39<31:43,  5.73s/it]16:46:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:46:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 34%|███▍      | 169/500 [15:44<31:01,  5.62s/it]16:46:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:46:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 34%|███▍      | 170/500 [15:48<27:37,  5.02s/it]16:46:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:46:31 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 34%|███▍      | 171/500 [15:55<31:09,  5.68s/it]16:46:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:46:38 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 34%|███▍      | 172/500 [16:02<32:26,  5.93s/it]16:46:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:46:46 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 35%|███▍      | 173/500 [16:09<35:12,  6.46s/it]16:46:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:46:50 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 35%|███▍      | 174/500 [16:13<31:10,  5.74s/it]16:46:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:46:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 35%|███▌      | 175/500 [16:23<36:52,  6.81s/it]16:47:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:47:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:47:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 35%|███▌      | 176/500 [16:27<32:06,  5.94s/it]16:47:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 35%|███▌      | 177/500 [16:30<27:40,  5.14s/it]16:47:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:47:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 36%|███▌      | 178/500 [16:37<31:09,  5.81s/it]16:47:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:47:20 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 36%|███▌      | 179/500 [16:43<31:24,  5.87s/it]16:47:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:47:24 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 36%|███▌      | 180/500 [16:47<28:26,  5.33s/it]16:47:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:47:30 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 36%|███▌      | 181/500 [16:53<29:28,  5.54s/it]16:47:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:47:41 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:47:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      " 36%|███▋      | 182/500 [17:04<38:10,  7.20s/it]16:47:45 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 37%|███▋      | 183/500 [17:09<33:42,  6.38s/it]16:47:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:47:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:47:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:47:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:47:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      " 37%|███▋      | 185/500 [17:25<36:50,  7.02s/it]16:48:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 37%|███▋      | 186/500 [17:29<31:30,  6.02s/it]16:48:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:48:10 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 37%|███▋      | 187/500 [17:33<29:10,  5.59s/it]16:48:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:48:18 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 38%|███▊      | 188/500 [17:42<33:41,  6.48s/it]16:48:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:48:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:48:30 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:48:31 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 38%|███▊      | 190/500 [17:58<35:02,  6.78s/it]16:48:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:48:39 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 38%|███▊      | 191/500 [18:02<31:35,  6.14s/it]16:48:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:48:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 38%|███▊      | 192/500 [18:10<33:54,  6.61s/it]16:48:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:48:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 39%|███▊      | 193/500 [18:16<33:13,  6.49s/it]16:48:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:48:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 39%|███▉      | 194/500 [18:20<28:43,  5.63s/it]16:49:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:49:06 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 39%|███▉      | 195/500 [18:30<36:06,  7.10s/it]16:49:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:49:13 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 39%|███▉      | 196/500 [18:36<34:23,  6.79s/it]16:49:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:49:18 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 39%|███▉      | 197/500 [18:42<31:59,  6.34s/it]16:49:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:49:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:49:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:49:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 40%|███▉      | 199/500 [18:51<27:00,  5.38s/it]16:49:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:49:35 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 40%|████      | 200/500 [18:58<29:43,  5.94s/it]16:49:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:49:39 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 40%|████      | 201/500 [19:02<26:16,  5.27s/it]16:49:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:49:44 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 40%|████      | 202/500 [19:08<26:53,  5.41s/it]16:49:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:49:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:49:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:49:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 41%|████      | 204/500 [19:20<27:21,  5.55s/it]16:50:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:50:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 41%|████      | 205/500 [19:27<29:18,  5.96s/it]16:50:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:50:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 41%|████      | 206/500 [19:33<29:13,  5.97s/it]16:50:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:50:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 41%|████▏     | 207/500 [19:38<27:11,  5.57s/it]16:50:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:50:20 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 42%|████▏     | 208/500 [19:43<27:17,  5.61s/it]16:50:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:50:30 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 42%|████▏     | 209/500 [19:54<34:30,  7.11s/it]16:50:36 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:50:36 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 42%|████▏     | 210/500 [20:00<32:41,  6.76s/it]16:50:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:50:40 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 42%|████▏     | 211/500 [20:04<28:07,  5.84s/it]16:50:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:50:45 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 42%|████▏     | 212/500 [20:09<26:38,  5.55s/it]16:50:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:50:49 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:50:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      " 43%|████▎     | 213/500 [20:13<24:33,  5.13s/it]16:50:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 43%|████▎     | 214/500 [20:16<21:52,  4.59s/it]16:50:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:50:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 43%|████▎     | 215/500 [20:22<23:56,  5.04s/it]16:51:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:51:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 43%|████▎     | 216/500 [20:29<26:00,  5.50s/it]16:51:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:51:10 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 43%|████▎     | 217/500 [20:33<24:18,  5.15s/it]16:51:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:51:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 44%|████▎     | 218/500 [20:37<23:01,  4.90s/it]16:51:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:51:22 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:51:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      " 44%|████▍     | 219/500 [20:45<27:16,  5.82s/it]16:51:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 44%|████▍     | 220/500 [20:49<23:33,  5.05s/it]16:51:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:51:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:51:34 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:51:34 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:51:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      " 44%|████▍     | 222/500 [21:01<24:41,  5.33s/it]16:51:41 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 45%|████▍     | 223/500 [21:05<22:24,  4.85s/it]16:51:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:51:50 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 45%|████▍     | 224/500 [21:14<28:50,  6.27s/it]16:51:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:51:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 45%|████▌     | 225/500 [21:23<32:48,  7.16s/it]16:52:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:52:10 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 45%|████▌     | 226/500 [21:33<36:37,  8.02s/it]16:52:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:52:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:52:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:52:15 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 46%|████▌     | 228/500 [21:42<27:27,  6.06s/it]16:52:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:52:23 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 46%|████▌     | 229/500 [21:47<25:27,  5.64s/it]16:52:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:52:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:52:30 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:52:31 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 46%|████▌     | 231/500 [21:58<24:02,  5.36s/it]16:52:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:52:38 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 46%|████▋     | 232/500 [22:01<21:51,  4.90s/it]16:52:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:52:42 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 47%|████▋     | 233/500 [22:06<20:45,  4.67s/it]16:52:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:52:50 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 47%|████▋     | 234/500 [22:13<24:24,  5.50s/it]16:52:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:52:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 47%|████▋     | 235/500 [22:17<22:17,  5.05s/it]16:53:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:53:01 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 47%|████▋     | 236/500 [22:24<24:47,  5.64s/it]16:53:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:53:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 47%|████▋     | 237/500 [22:32<27:46,  6.34s/it]16:53:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:53:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 48%|████▊     | 238/500 [22:37<25:54,  5.93s/it]16:53:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:53:20 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 48%|████▊     | 239/500 [22:44<26:44,  6.15s/it]16:53:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:53:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 48%|████▊     | 240/500 [22:50<27:15,  6.29s/it]16:53:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:53:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:53:35 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 48%|████▊     | 241/500 [22:58<29:07,  6.75s/it]16:53:38 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 48%|████▊     | 242/500 [23:01<24:36,  5.72s/it]16:53:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:53:46 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 49%|████▊     | 243/500 [23:10<28:37,  6.68s/it]16:53:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:53:51 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 49%|████▉     | 244/500 [23:15<25:36,  6.00s/it]16:53:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:53:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 49%|████▉     | 245/500 [23:19<23:47,  5.60s/it]16:54:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:54:01 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 49%|████▉     | 246/500 [23:25<23:30,  5.55s/it]16:54:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:54:06 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 49%|████▉     | 247/500 [23:29<22:10,  5.26s/it]16:54:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:54:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 50%|████▉     | 248/500 [23:36<23:20,  5.56s/it]16:54:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:54:16 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 50%|████▉     | 249/500 [23:40<21:28,  5.13s/it]16:54:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:54:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 50%|█████     | 250/500 [23:45<21:34,  5.18s/it]16:54:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:54:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 50%|█████     | 251/500 [23:50<21:44,  5.24s/it]16:54:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:54:31 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 50%|█████     | 252/500 [23:55<20:56,  5.07s/it]16:54:36 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:54:36 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 51%|█████     | 253/500 [24:00<20:14,  4.92s/it]16:54:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:54:42 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 51%|█████     | 254/500 [24:06<21:59,  5.36s/it]16:54:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:54:49 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 51%|█████     | 255/500 [24:13<23:38,  5.79s/it]16:54:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:54:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 51%|█████     | 256/500 [24:17<20:58,  5.16s/it]16:54:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:54:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 51%|█████▏    | 257/500 [24:23<21:56,  5.42s/it]16:55:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:55:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 52%|█████▏    | 258/500 [24:29<22:40,  5.62s/it]16:55:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:55:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 52%|█████▏    | 259/500 [24:36<24:15,  6.04s/it]16:55:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:55:17 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 52%|█████▏    | 260/500 [24:41<23:28,  5.87s/it]16:55:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:55:23 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 52%|█████▏    | 261/500 [24:47<22:52,  5.74s/it]16:55:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:55:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 52%|█████▏    | 262/500 [24:50<20:23,  5.14s/it]16:55:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:55:31 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:55:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      " 53%|█████▎    | 263/500 [24:54<18:25,  4.66s/it]16:55:34 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 53%|█████▎    | 264/500 [24:57<16:47,  4.27s/it]16:55:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:55:41 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 53%|█████▎    | 265/500 [25:04<19:46,  5.05s/it]16:55:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:55:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 53%|█████▎    | 266/500 [25:11<21:39,  5.55s/it]16:55:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:55:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:55:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:55:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 54%|█████▎    | 268/500 [25:20<19:11,  4.96s/it]16:56:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:56:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 54%|█████▍    | 269/500 [25:26<19:54,  5.17s/it]16:56:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:56:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 54%|█████▍    | 270/500 [25:35<24:33,  6.41s/it]16:56:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:56:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:56:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:56:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 54%|█████▍    | 272/500 [25:48<23:36,  6.21s/it]16:56:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:56:31 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 55%|█████▍    | 273/500 [25:54<23:19,  6.16s/it]16:56:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:56:39 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:56:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      " 55%|█████▍    | 274/500 [26:03<26:28,  7.03s/it]16:56:43 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 55%|█████▌    | 275/500 [26:07<23:13,  6.19s/it]16:56:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:56:51 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 55%|█████▌    | 276/500 [26:14<24:04,  6.45s/it]16:56:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:56:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:56:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:56:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 55%|█████▌    | 277/500 [26:20<23:20,  6.28s/it]16:57:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      " 56%|█████▌    | 278/500 [26:24<19:53,  5.38s/it]16:57:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 56%|█████▌    | 279/500 [26:28<18:29,  5.02s/it]16:57:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:57:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 56%|█████▌    | 280/500 [26:35<20:25,  5.57s/it]16:57:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:57:15 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 56%|█████▌    | 281/500 [26:39<18:48,  5.15s/it]16:57:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:57:23 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 56%|█████▋    | 282/500 [26:46<21:07,  5.82s/it]16:57:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:57:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 57%|█████▋    | 283/500 [26:52<21:10,  5.85s/it]16:57:36 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:57:37 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 57%|█████▋    | 284/500 [27:00<23:37,  6.56s/it]16:57:43 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:57:44 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 57%|█████▋    | 285/500 [27:08<24:27,  6.82s/it]16:57:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:57:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:57:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 57%|█████▋    | 286/500 [27:15<25:15,  7.08s/it]16:57:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:57:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:57:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:57:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 57%|█████▋    | 287/500 [27:19<21:30,  6.06s/it]16:57:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 58%|█████▊    | 289/500 [27:26<16:19,  4.64s/it]16:58:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:58:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 58%|█████▊    | 290/500 [27:32<17:46,  5.08s/it]16:58:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:58:20 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 58%|█████▊    | 291/500 [27:43<24:11,  6.95s/it]16:58:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:58:23 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:58:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      " 58%|█████▊    | 292/500 [27:47<20:38,  5.95s/it]16:58:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 59%|█████▊    | 293/500 [27:50<17:50,  5.17s/it]16:58:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:58:39 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:58:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      " 59%|█████▉    | 294/500 [28:02<24:55,  7.26s/it]16:58:42 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 59%|█████▉    | 295/500 [28:06<20:54,  6.12s/it]16:58:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:58:46 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 59%|█████▉    | 296/500 [28:10<18:31,  5.45s/it]16:58:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:58:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 59%|█████▉    | 297/500 [28:16<19:05,  5.64s/it]16:58:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:58:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:58:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:59:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 60%|█████▉    | 299/500 [28:27<18:14,  5.44s/it]16:59:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:59:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 60%|██████    | 300/500 [28:35<20:57,  6.29s/it]16:59:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:59:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:59:18 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:59:18 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 61%|██████    | 303/500 [28:49<16:33,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing HOUSEHOLD_1_081_TX_3_validation: 'AutoARIMA' object has no attribute '_model_call'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:59:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:59:30 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 61%|██████    | 304/500 [28:53<15:48,  4.84s/it]16:59:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:59:37 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 61%|██████    | 305/500 [29:01<18:50,  5.80s/it]16:59:43 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:59:43 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 61%|██████    | 306/500 [29:07<18:09,  5.62s/it]16:59:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:59:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 61%|██████▏   | 307/500 [29:10<16:18,  5.07s/it]16:59:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:59:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 62%|██████▏   | 308/500 [29:19<19:26,  6.07s/it]17:00:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:00:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 62%|██████▏   | 309/500 [29:26<20:24,  6.41s/it]17:00:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:00:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 62%|██████▏   | 310/500 [29:32<20:15,  6.40s/it]17:00:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:00:15 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 62%|██████▏   | 311/500 [29:38<19:49,  6.30s/it]17:00:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:00:20 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 62%|██████▏   | 312/500 [29:44<18:45,  5.99s/it]17:00:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:00:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 63%|██████▎   | 313/500 [29:48<17:07,  5.49s/it]17:00:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:00:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 63%|██████▎   | 314/500 [29:53<16:20,  5.27s/it]17:00:36 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:00:36 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 63%|██████▎   | 315/500 [30:00<17:37,  5.72s/it]17:00:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:00:41 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 63%|██████▎   | 316/500 [30:04<16:37,  5.42s/it]17:00:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:00:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 63%|██████▎   | 317/500 [30:11<17:56,  5.88s/it]17:00:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:00:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 64%|██████▎   | 318/500 [30:17<17:28,  5.76s/it]17:00:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:00:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 64%|██████▍   | 319/500 [30:20<15:25,  5.11s/it]17:01:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:01:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:01:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:01:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 64%|██████▍   | 321/500 [30:30<14:39,  4.91s/it]17:01:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:01:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:01:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      " 64%|██████▍   | 322/500 [30:37<16:06,  5.43s/it]17:01:17 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 65%|██████▍   | 323/500 [30:40<14:10,  4.81s/it]17:01:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:01:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:01:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:01:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 65%|██████▌   | 325/500 [30:54<16:00,  5.49s/it]17:01:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:01:35 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 65%|██████▌   | 326/500 [30:58<14:57,  5.16s/it]17:01:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:01:42 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 65%|██████▌   | 327/500 [31:05<16:32,  5.73s/it]17:01:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:01:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:01:49 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:01:49 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 66%|██████▌   | 329/500 [31:16<15:19,  5.38s/it]17:01:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:01:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 66%|██████▌   | 330/500 [31:22<15:34,  5.49s/it]17:02:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:02:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 66%|██████▌   | 331/500 [31:26<14:01,  4.98s/it]17:02:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:02:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:02:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 66%|██████▋   | 332/500 [31:34<16:25,  5.87s/it]17:02:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 67%|██████▋   | 333/500 [31:37<14:26,  5.19s/it]17:02:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:02:22 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 67%|██████▋   | 334/500 [31:46<16:53,  6.11s/it]17:02:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:02:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 67%|██████▋   | 335/500 [31:50<15:22,  5.59s/it]17:02:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:02:38 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 67%|██████▋   | 336/500 [32:02<20:42,  7.57s/it]17:02:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:02:43 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 67%|██████▋   | 337/500 [32:06<17:31,  6.45s/it]17:02:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:02:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 68%|██████▊   | 338/500 [32:11<16:16,  6.03s/it]17:02:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:02:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 68%|██████▊   | 339/500 [32:16<15:29,  5.77s/it]17:03:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:03:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 68%|██████▊   | 340/500 [32:23<16:12,  6.08s/it]17:03:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:03:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 68%|██████▊   | 341/500 [32:27<14:46,  5.58s/it]17:03:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:03:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 68%|██████▊   | 342/500 [32:38<18:14,  6.93s/it]17:03:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:03:20 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 69%|██████▊   | 343/500 [32:43<17:10,  6.56s/it]17:03:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:03:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 69%|██████▉   | 344/500 [32:48<15:33,  5.98s/it]17:03:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:03:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:03:35 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:03:35 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:03:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      " 69%|██████▉   | 346/500 [33:02<15:36,  6.08s/it]17:03:42 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 69%|██████▉   | 347/500 [33:05<13:29,  5.29s/it]17:03:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:03:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 70%|██████▉   | 348/500 [33:11<13:36,  5.37s/it]17:03:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:03:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 70%|██████▉   | 349/500 [33:18<14:44,  5.86s/it]17:03:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:03:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 70%|███████   | 350/500 [33:21<12:57,  5.18s/it]17:04:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:04:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 70%|███████   | 351/500 [33:28<14:08,  5.70s/it]17:04:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:04:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 70%|███████   | 352/500 [33:33<13:21,  5.42s/it]17:04:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:04:15 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 71%|███████   | 353/500 [33:38<13:05,  5.34s/it]17:04:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:04:19 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 71%|███████   | 354/500 [33:42<11:51,  4.88s/it]17:04:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:04:26 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:04:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      " 71%|███████   | 355/500 [33:50<14:21,  5.94s/it]17:04:30 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 71%|███████   | 356/500 [33:54<12:27,  5.19s/it]17:04:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:04:41 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 71%|███████▏  | 357/500 [34:05<16:31,  6.94s/it]17:04:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:04:45 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:04:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:04:45 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 72%|███████▏  | 359/500 [34:12<12:11,  5.19s/it]17:04:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:05:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 72%|███████▏  | 360/500 [34:24<16:44,  7.17s/it]17:05:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:05:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 72%|███████▏  | 361/500 [34:28<14:55,  6.44s/it]17:05:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:05:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:05:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 72%|███████▏  | 362/500 [34:33<13:19,  5.80s/it]17:05:13 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 73%|███████▎  | 363/500 [34:36<11:54,  5.22s/it]17:05:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:05:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 73%|███████▎  | 364/500 [34:45<13:59,  6.17s/it]17:05:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:05:28 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 73%|███████▎  | 365/500 [34:52<14:17,  6.35s/it]17:05:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:05:38 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:05:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      " 73%|███████▎  | 366/500 [35:01<16:29,  7.38s/it]17:05:41 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 73%|███████▎  | 367/500 [35:05<13:50,  6.24s/it]17:05:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:05:50 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 74%|███████▎  | 368/500 [35:14<15:50,  7.20s/it]17:05:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:05:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 74%|███████▍  | 369/500 [35:19<13:57,  6.39s/it]17:05:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:05:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:06:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:06:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 74%|███████▍  | 371/500 [35:26<10:48,  5.03s/it]17:06:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:06:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:06:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:06:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 75%|███████▍  | 373/500 [35:41<12:24,  5.86s/it]17:06:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:06:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:06:22 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:06:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      " 75%|███████▍  | 374/500 [35:45<11:08,  5.31s/it]17:06:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:06:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 75%|███████▌  | 376/500 [35:53<09:15,  4.48s/it]17:06:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:06:40 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:06:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:06:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:06:41 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:06:41 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:06:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      " 75%|███████▌  | 377/500 [36:04<13:42,  6.69s/it]17:06:45 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 76%|███████▌  | 380/500 [36:15<09:09,  4.58s/it]17:06:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:06:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 76%|███████▌  | 381/500 [36:22<10:22,  5.23s/it]17:07:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:07:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 76%|███████▋  | 382/500 [36:28<10:47,  5.49s/it]17:07:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:07:15 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 77%|███████▋  | 383/500 [36:39<14:14,  7.30s/it]17:07:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:07:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 77%|███████▋  | 384/500 [36:45<13:15,  6.86s/it]17:07:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:07:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 77%|███████▋  | 385/500 [36:51<12:29,  6.52s/it]17:07:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:07:34 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 77%|███████▋  | 386/500 [36:58<12:54,  6.79s/it]17:07:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:07:40 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 77%|███████▋  | 387/500 [37:04<12:05,  6.42s/it]17:07:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:07:44 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 78%|███████▊  | 388/500 [37:08<10:56,  5.87s/it]17:07:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:07:50 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 78%|███████▊  | 389/500 [37:14<10:49,  5.85s/it]17:07:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:07:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 78%|███████▊  | 390/500 [37:20<10:37,  5.79s/it]17:08:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:08:01 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 78%|███████▊  | 391/500 [37:24<09:38,  5.31s/it]17:08:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:08:06 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 78%|███████▊  | 392/500 [37:31<10:24,  5.78s/it]17:08:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:08:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:08:13 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:08:13 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 79%|███████▉  | 394/500 [37:40<08:56,  5.06s/it]17:08:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:08:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:08:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:08:22 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 79%|███████▉  | 396/500 [37:48<07:51,  4.53s/it]17:08:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:08:31 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 79%|███████▉  | 397/500 [37:55<08:41,  5.06s/it]17:08:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:08:35 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 80%|███████▉  | 398/500 [37:58<07:56,  4.67s/it]17:08:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:08:42 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 80%|███████▉  | 399/500 [38:06<09:18,  5.53s/it]17:08:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:08:46 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 80%|████████  | 400/500 [38:09<08:14,  4.94s/it]17:08:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:08:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 80%|████████  | 401/500 [38:16<09:00,  5.46s/it]17:08:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:08:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:08:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:08:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 81%|████████  | 403/500 [38:24<07:34,  4.68s/it]17:09:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:09:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 81%|████████  | 404/500 [38:31<08:23,  5.24s/it]17:09:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:09:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 81%|████████  | 405/500 [38:38<09:02,  5.72s/it]17:09:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:09:22 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 81%|████████  | 406/500 [38:45<09:43,  6.21s/it]17:09:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:09:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 81%|████████▏ | 407/500 [38:52<10:11,  6.58s/it]17:09:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:09:39 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:09:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:09:39 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 82%|████████▏ | 409/500 [39:06<09:40,  6.38s/it]17:09:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:09:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:09:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:09:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 82%|████████▏ | 410/500 [39:10<08:41,  5.79s/it]17:09:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      " 82%|████████▏ | 411/500 [39:14<07:31,  5.08s/it]17:09:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 82%|████████▏ | 412/500 [39:17<06:45,  4.61s/it]17:10:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:10:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 83%|████████▎ | 413/500 [39:23<07:05,  4.90s/it]17:10:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:10:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 83%|████████▎ | 414/500 [39:29<07:28,  5.21s/it]17:10:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:10:10 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 83%|████████▎ | 415/500 [39:34<07:08,  5.05s/it]17:10:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:10:17 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:10:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      " 83%|████████▎ | 416/500 [39:40<07:45,  5.54s/it]17:10:20 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:10:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      " 83%|████████▎ | 417/500 [39:44<06:45,  4.88s/it]17:10:24 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 84%|████████▎ | 418/500 [39:48<06:16,  4.59s/it]17:10:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:10:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:10:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      " 84%|████████▍ | 419/500 [39:53<06:25,  4.76s/it]17:10:33 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 84%|████████▍ | 420/500 [39:56<05:47,  4.34s/it]17:10:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:10:38 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 84%|████████▍ | 421/500 [40:01<05:56,  4.51s/it]17:10:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:10:49 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 84%|████████▍ | 422/500 [40:13<08:51,  6.82s/it]17:10:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:10:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 85%|████████▍ | 423/500 [40:17<07:38,  5.95s/it]17:10:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:10:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 85%|████████▍ | 424/500 [40:21<06:42,  5.30s/it]17:11:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:11:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 85%|████████▌ | 425/500 [40:27<07:05,  5.68s/it]17:11:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:11:10 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 85%|████████▌ | 426/500 [40:34<07:18,  5.93s/it]17:11:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:11:16 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 85%|████████▌ | 427/500 [40:39<07:03,  5.80s/it]17:11:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:11:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:11:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:11:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      " 86%|████████▌ | 428/500 [40:49<08:12,  6.84s/it]17:11:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:11:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 86%|████████▌ | 430/500 [40:55<05:51,  5.02s/it]17:11:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:11:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:11:39 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:11:39 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 86%|████████▋ | 432/500 [41:05<05:30,  4.86s/it]17:11:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:11:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 87%|████████▋ | 433/500 [41:17<07:36,  6.81s/it]17:12:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:12:01 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:12:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      " 87%|████████▋ | 434/500 [41:25<08:00,  7.29s/it]17:12:06 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 87%|████████▋ | 435/500 [41:29<06:43,  6.21s/it]17:12:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:12:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:12:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:12:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 87%|████████▋ | 437/500 [41:36<05:01,  4.79s/it]17:12:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:12:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 88%|████████▊ | 438/500 [41:45<06:17,  6.09s/it]17:12:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:12:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 88%|████████▊ | 439/500 [41:50<05:57,  5.85s/it]17:12:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:12:31 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 88%|████████▊ | 440/500 [41:55<05:28,  5.47s/it]17:12:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:12:35 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 88%|████████▊ | 441/500 [41:59<04:54,  4.99s/it]17:12:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:12:39 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 88%|████████▊ | 442/500 [42:03<04:32,  4.69s/it]17:12:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:12:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 89%|████████▊ | 443/500 [42:12<05:44,  6.05s/it]17:12:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:12:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:12:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      " 89%|████████▉ | 444/500 [42:19<05:58,  6.41s/it]17:12:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 89%|████████▉ | 445/500 [42:23<05:07,  5.59s/it]17:13:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:13:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 89%|████████▉ | 446/500 [42:28<04:50,  5.38s/it]17:13:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:13:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 89%|████████▉ | 447/500 [42:32<04:36,  5.21s/it]17:13:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:13:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 90%|████████▉ | 448/500 [42:38<04:37,  5.34s/it]17:13:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:13:20 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 90%|████████▉ | 449/500 [42:43<04:28,  5.27s/it]17:13:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:13:24 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 90%|█████████ | 450/500 [42:47<04:09,  4.98s/it]17:13:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:13:30 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 90%|█████████ | 451/500 [42:53<04:18,  5.28s/it]17:13:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:13:34 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 90%|█████████ | 452/500 [42:57<03:51,  4.83s/it]17:13:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:13:38 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 91%|█████████ | 453/500 [43:01<03:35,  4.59s/it]17:13:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:13:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 91%|█████████ | 454/500 [43:11<04:44,  6.18s/it]17:13:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:13:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 91%|█████████ | 455/500 [43:18<04:45,  6.35s/it]17:13:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:13:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 91%|█████████ | 456/500 [43:22<04:14,  5.78s/it]17:14:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:14:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 91%|█████████▏| 457/500 [43:29<04:23,  6.13s/it]17:14:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:14:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:14:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:14:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 92%|█████████▏| 459/500 [43:38<03:26,  5.03s/it]17:14:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:14:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 92%|█████████▏| 460/500 [43:45<03:53,  5.83s/it]17:14:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:14:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 92%|█████████▏| 461/500 [43:50<03:38,  5.62s/it]17:14:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:14:31 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 92%|█████████▏| 462/500 [43:55<03:16,  5.18s/it]17:14:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:14:37 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 93%|█████████▎| 463/500 [44:01<03:20,  5.41s/it]17:14:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:14:41 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 93%|█████████▎| 464/500 [44:04<02:55,  4.87s/it]17:14:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:14:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 93%|█████████▎| 465/500 [44:11<03:10,  5.44s/it]17:14:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:14:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 93%|█████████▎| 466/500 [44:20<03:39,  6.45s/it]17:15:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:15:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:15:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      " 93%|█████████▎| 467/500 [44:26<03:29,  6.34s/it]17:15:06 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 94%|█████████▎| 468/500 [44:29<02:55,  5.47s/it]17:15:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:15:13 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 94%|█████████▍| 469/500 [44:37<03:10,  6.14s/it]17:15:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:15:20 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 94%|█████████▍| 470/500 [44:43<03:07,  6.27s/it]17:15:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:15:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 94%|█████████▍| 471/500 [44:48<02:49,  5.84s/it]17:15:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:15:30 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 94%|█████████▍| 472/500 [44:54<02:39,  5.70s/it]17:15:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:15:34 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 95%|█████████▍| 473/500 [44:58<02:19,  5.16s/it]17:15:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:15:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:15:41 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:15:41 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 95%|█████████▌| 475/500 [45:08<02:03,  4.94s/it]17:15:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:15:50 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 95%|█████████▌| 476/500 [45:14<02:04,  5.21s/it]17:15:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:15:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:15:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      " 95%|█████████▌| 477/500 [45:20<02:08,  5.60s/it]17:16:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 96%|█████████▌| 478/500 [45:24<01:49,  4.95s/it]17:16:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:16:10 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 96%|█████████▌| 479/500 [45:33<02:14,  6.42s/it]17:16:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:16:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 96%|█████████▌| 480/500 [45:37<01:54,  5.72s/it]17:16:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:16:18 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 96%|█████████▌| 481/500 [45:41<01:37,  5.11s/it]17:16:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:16:24 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 96%|█████████▋| 482/500 [45:48<01:40,  5.57s/it]17:16:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:16:30 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 97%|█████████▋| 483/500 [45:53<01:34,  5.53s/it]17:16:33 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:16:34 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 97%|█████████▋| 484/500 [45:57<01:21,  5.07s/it]17:16:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:16:42 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 97%|█████████▋| 485/500 [46:06<01:30,  6.05s/it]17:16:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:16:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 97%|█████████▋| 486/500 [46:17<01:45,  7.53s/it]17:16:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:16:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 97%|█████████▋| 487/500 [46:21<01:25,  6.55s/it]17:17:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:17:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:17:01 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 98%|█████████▊| 488/500 [46:25<01:09,  5.75s/it]17:17:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 98%|█████████▊| 489/500 [46:28<00:55,  5.04s/it]17:17:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:17:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 98%|█████████▊| 490/500 [46:34<00:54,  5.45s/it]17:17:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:17:20 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 98%|█████████▊| 491/500 [46:43<00:57,  6.41s/it]17:17:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:17:26 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:17:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      " 98%|█████████▊| 492/500 [46:49<00:49,  6.23s/it]17:17:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 99%|█████████▊| 493/500 [46:53<00:38,  5.55s/it]17:17:33 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:17:33 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:17:33 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:17:33 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 99%|█████████▉| 494/500 [46:57<00:29,  4.98s/it]17:17:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:17:40 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 99%|█████████▉| 496/500 [47:00<00:14,  3.54s/it]17:17:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:17:41 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 99%|█████████▉| 497/500 [47:01<00:08,  2.97s/it]17:17:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:17:42 - cmdstanpy - INFO - Chain [1] done processing\n",
      "100%|█████████▉| 498/500 [47:02<00:04,  2.29s/it]17:17:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:17:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:17:45 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:17:45 - cmdstanpy - INFO - Chain [1] done processing\n",
      "100%|██████████| 500/500 [47:05<00:00,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ARIMA  Exponential Smoothing   Prophet\n",
      "RMSE   1.313787               1.301794  1.386556\n",
      "MAE    0.983631               0.977356  1.069421\n",
      "RMSSE  0.993854               0.995023  1.018052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_single_id(id_value, df_prepared, train_test_split):\n",
    "    \"\"\"Process a single ID - will run in parallel\"\"\"\n",
    "    try:\n",
    "        target, covariates = create_timeseries(df_prepared, id_value)\n",
    "        split_point = int(len(target) * train_test_split)\n",
    "        train, test = target[:split_point], target[split_point:]\n",
    "        cov_train, cov_test = covariates[:split_point], covariates[split_point:]\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # ARIMA\n",
    "        model = AutoARIMA()\n",
    "        model.fit(train)\n",
    "        pred = model.predict(len(test))\n",
    "        results['ARIMA'] = safe_metrics(train, test, pred)\n",
    "        \n",
    "        # Exponential Smoothing\n",
    "        model = ExponentialSmoothing(seasonal_periods=7)\n",
    "        model.fit(train)\n",
    "        pred = model.predict(len(test))\n",
    "        results['Exponential Smoothing'] = safe_metrics(train, test, pred)\n",
    "        \n",
    "        # Prophet\n",
    "        model = Prophet()\n",
    "        model.fit(train, future_covariates=cov_train)\n",
    "        pred = model.predict(len(test), future_covariates=cov_test)\n",
    "        results['Prophet'] = safe_metrics(train, test, pred)\n",
    "        \n",
    "        return id_value, results\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {id_value}: {e}\")\n",
    "        return id_value, None\n",
    "\n",
    "# Parallel execution\n",
    "all_results = {}\n",
    "n_workers = 6  # Adjust based on your CPU cores\n",
    "\n",
    "np.random.seed(42)  # or any integer you prefer\n",
    "sample_ids = np.random.choice(unique_ids, size=min(500, len(unique_ids)), replace=False)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=n_workers) as executor:\n",
    "    future_to_id = {\n",
    "        executor.submit(process_single_id, id_val, df_prepared, TRAIN_TEST_SPLIT): id_val \n",
    "        for id_val in sample_ids\n",
    "    }\n",
    "    \n",
    "    for future in tqdm(as_completed(future_to_id), total=len(sample_ids)):\n",
    "        id_value, results = future.result()\n",
    "        if results is not None:\n",
    "            all_results[id_value] = results\n",
    "\n",
    "# Rest of your code remains the same\n",
    "global_results = {}\n",
    "for product, models in all_results.items():\n",
    "    for model_name, metrics in models.items():\n",
    "        if model_name not in global_results:\n",
    "            global_results[model_name] = {'RMSE': [], 'MAE': [], 'RMSSE': []}\n",
    "        for metric_name, value in metrics.items():\n",
    "            global_results[model_name][metric_name].append(float(value))\n",
    "\n",
    "global_averages = {\n",
    "    model_name: {metric: np.mean(values) for metric, values in metrics.items()}\n",
    "    for model_name, metrics in global_results.items()\n",
    "}\n",
    "print(pd.DataFrame(global_averages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f3e363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Model Training and Evaluation\n",
    "# ============================================\n",
    "def evaluate_models(target, covariates, forecast_horizon=60):\n",
    "    \"\"\"\n",
    "    Train and evaluate multiple forecasting models\n",
    "    \"\"\"\n",
    "    # Split data\n",
    "    split_point = int(len(target) * TRAIN_TEST_SPLIT)\n",
    "    train, test = target[:split_point], target[split_point:]\n",
    "    \n",
    "    if covariates is not None:\n",
    "        cov_train, cov_test = covariates[:split_point], covariates[split_point:]\n",
    "        # For past covariates, we need train + test\n",
    "        cov_past_full = covariates[:split_point + len(test)]\n",
    "    else:\n",
    "        cov_train, cov_test = None, None\n",
    "        cov_past_full = None\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # ============================================\n",
    "    # 4. Random Forest (ML)\n",
    "    # ============================================\n",
    "    try:\n",
    "        print(\"  Training Random Forest...\")\n",
    "        from darts.models import RandomForestModel  # Import the correct model\n",
    "        \n",
    "        model = RandomForestModel(\n",
    "            lags=7,#30,\n",
    "            #lags_future_covariates=[0, 1, 2, 3, 4, 5, 6, 7],\n",
    "            output_chunk_length=1,\n",
    "            n_estimators=100\n",
    "        )\n",
    "        \n",
    "        # Pass future_covariates to fit and predict\n",
    "        if cov_train is not None:\n",
    "            model.fit(train, future_covariates=cov_train)\n",
    "            pred = model.predict(len(test), future_covariates=cov_test)\n",
    "        else:\n",
    "            # If no covariates, create a model without them\n",
    "            model = RandomForestModel(\n",
    "                lags=30,\n",
    "                output_chunk_length=1,\n",
    "                n_estimators=100\n",
    "            )\n",
    "            model.fit(train)\n",
    "            pred = model.predict(len(test))\n",
    "        \n",
    "        results['Random Forest'] = safe_metrics(test, pred, 'Random Forest')\n",
    "    except Exception as e:\n",
    "        print(f\"  Random Forest failed: {e}\")\n",
    "        results['Random Forest'] = {'Error': str(e)}\n",
    "    \n",
    "    # ============================================\n",
    "    # 5. LightGBM (ML)\n",
    "    # ============================================\n",
    "    try:\n",
    "        print(\"  Training LightGBM...\")\n",
    "        model = LightGBMModel(\n",
    "            lags=7,#30,\n",
    "            #lags_future_covariates=[0, 1, 2, 3, 4, 5, 6, 7],\n",
    "            output_chunk_length=1\n",
    "        )\n",
    "        \n",
    "        # Pass future_covariates to fit and predict\n",
    "        if cov_train is not None:\n",
    "            model.fit(train, future_covariates=cov_train)\n",
    "            pred = model.predict(len(test), future_covariates=cov_test)\n",
    "        else:\n",
    "            # If no covariates, create a model without them\n",
    "            model = LightGBMModel(\n",
    "                lags=30,\n",
    "                output_chunk_length=1\n",
    "            )\n",
    "            model.fit(train)\n",
    "            pred = model.predict(len(test))\n",
    "        \n",
    "        pred = scaler.inverse_transform(pred)\n",
    "        results['LightGBM'] = safe_metrics(test, pred, 'LightGBM')\n",
    "    except Exception as e:\n",
    "        print(f\"  LightGBM failed: {e}\")\n",
    "        results['LightGBM'] = {'Error': str(e)}\n",
    "    \n",
    "    # ============================================\n",
    "    # 6. XGBoost (ML)\n",
    "    # ============================================\n",
    "    try:\n",
    "        print(\"  Training XGBoost...\")\n",
    "        model = XGBModel(\n",
    "            lags=7,#30,\n",
    "            #lags_future_covariates=[0, 1, 2, 3, 4, 5, 6, 7],\n",
    "            output_chunk_length=1\n",
    "        )\n",
    "        \n",
    "        # Pass future_covariates to fit and predict\n",
    "        if cov_train is not None:\n",
    "            model.fit(train, future_covariates=cov_train)\n",
    "            pred = model.predict(len(test), future_covariates=cov_test)\n",
    "        else:\n",
    "            # If no covariates, create a model without them\n",
    "            model = XGBModel(\n",
    "                lags=30,\n",
    "                output_chunk_length=1\n",
    "            )\n",
    "            model.fit(train)\n",
    "            pred = model.predict(len(test))\n",
    "        \n",
    "        pred = scaler.inverse_transform(pred)\n",
    "        results['XGBoost'] = safe_metrics(test, pred, 'XGBoost')\n",
    "    except Exception as e:\n",
    "        print(f\"  XGBoost failed: {e}\")\n",
    "        results['XGBoost'] = {'Error': str(e)}\n",
    "    \n",
    "    # ============================================\n",
    "    # 8. TCN (Deep Learning) - only if enough data\n",
    "    # ============================================\n",
    "    try:\n",
    "        input_chunk = min(21, len(train) // 2)\n",
    "        print(f\"  Training TCN (input_chunk_length={input_chunk})...\")\n",
    "        model = TCNModel(\n",
    "            input_chunk_length=input_chunk,\n",
    "            output_chunk_length=1,\n",
    "            n_epochs=50,\n",
    "            batch_size=32,\n",
    "            random_state=42,\n",
    "            pl_trainer_kwargs={\"accelerator\": \"cpu\"}  # Force CPU to avoid MPS issues\n",
    "        )\n",
    "        model.fit(train, verbose=False)\n",
    "        pred = model.predict(len(test))\n",
    "        \n",
    "        results['TCN'] = safe_metrics(test, pred, 'TCN')\n",
    "    except Exception as e:\n",
    "        print(f\"  TCN failed: {e}\")\n",
    "        results['TCN'] = {'Error': str(e)}\n",
    "    \n",
    "    # ============================================\n",
    "    # 9. NHiTS (Deep Learning) - State-of-the-art\n",
    "    # ============================================\n",
    "    try:\n",
    "        input_chunk = min(21, len(train) // 2)\n",
    "        print(f\"  Training NHiTS (input_chunk_length={input_chunk})...\")\n",
    "        model = NHiTSModel(\n",
    "            input_chunk_length=input_chunk,\n",
    "            output_chunk_length=1,\n",
    "            n_epochs=50,\n",
    "            batch_size=32,\n",
    "            random_state=42,\n",
    "            pl_trainer_kwargs={\"accelerator\": \"cpu\"}  # Force CPU to avoid MPS issues\n",
    "        )\n",
    "        model.fit(train, verbose=False)\n",
    "        pred = model.predict(len(test))\n",
    "        \n",
    "        results['NHiTS'] = safe_metrics(test, pred, 'NHiTS')\n",
    "    except Exception as e:\n",
    "        print(f\"  NHiTS failed: {e}\")\n",
    "        results['NHiTS'] = {'Error': str(e)}\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ============================================\n",
    "# Main Execution\n",
    "# ============================================\n",
    "def main(df):\n",
    "    \"\"\"\n",
    "    Main function to run forecasting experiments\n",
    "    \"\"\"\n",
    "    print(\"Preparing data...\")\n",
    "    df_prepared = prepare_data(df)\n",
    "    \n",
    "    # Get unique IDs (item x store combinations)\n",
    "    unique_ids = df_prepared['id'].unique()\n",
    "    \n",
    "    # Test on first few IDs (you can increase this)\n",
    "    test_ids = unique_ids[:1]  # Test on 3 items\n",
    "    \n",
    "    all_results = {}\n",
    "    \n",
    "    for id_value in test_ids:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Processing ID: {id_value}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        try:\n",
    "            target, covariates = create_timeseries(df_prepared, id_value)\n",
    "            print(f\"Time series length: {len(target)}\")\n",
    "            \n",
    "            results = evaluate_models(target, covariates)\n",
    "            all_results[id_value] = results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {id_value}: {e}\")\n",
    "            all_results[id_value] = {'Error': str(e)}\n",
    "    \n",
    "    # ============================================\n",
    "    # Display Results\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"RESULTS SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for id_value, results in all_results.items():\n",
    "        print(f\"\\n{id_value}:\")\n",
    "        if 'Error' in results:\n",
    "            print(f\"  Error: {results['Error']}\")\n",
    "        else:\n",
    "            results_df = pd.DataFrame(results).T\n",
    "            print(results_df.to_string())\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "# ============================================\n",
    "# Usage\n",
    "# ============================================\n",
    "# Assuming your dataframe is called 'df'\n",
    "# results = main(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9e03cc",
   "metadata": {},
   "source": [
    "### ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82c00985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "def forecast_with_ml(df, id_col='id', date_col='date', target_col='sales', \n",
    "                     forecast_horizon=60, train_ratio=0.8):\n",
    "    \"\"\"Forecast time series using XGBoost with batch processing\"\"\"\n",
    "    \n",
    "    # Prepare data\n",
    "    df = df.copy()\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "    df = df.sort_values([id_col, date_col]).reset_index(drop=True)\n",
    "    \n",
    "    # Sample IDs\n",
    "    np.random.seed(42)\n",
    "    sample_ids = np.random.choice(unique_ids, size=min(500, len(unique_ids)), replace=False)\n",
    "    df = df[df[id_col].isin(sample_ids)]\n",
    "    \n",
    "    # Create train/test split indicator\n",
    "    df['row_num'] = df.groupby(id_col).cumcount()\n",
    "    df['total_rows'] = df.groupby(id_col)[id_col].transform('count')\n",
    "    df['split_point'] = (df['total_rows'] * train_ratio).astype(int)\n",
    "    df['is_train'] = df['row_num'] < df['split_point']\n",
    "    df['is_test'] = (df['row_num'] >= df['split_point']) & (df['row_num'] < df['split_point'] + forecast_horizon)\n",
    "    \n",
    "    # Encode categorical columns\n",
    "    feature_cols = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', \n",
    "                    'd', 'wday', 'month', 'year', 'event_name_1', 'event_type_1', \n",
    "                    'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI']\n",
    "    feature_cols = [c for c in feature_cols if c in df.columns]\n",
    "    \n",
    "    df_encoded = df.copy()\n",
    "    for col in feature_cols:\n",
    "        if df_encoded[col].dtype == 'object':\n",
    "            df_encoded[col] = pd.Categorical(df_encoded[col]).codes\n",
    "    \n",
    "    # Train model on all training data (batch)\n",
    "    train_mask = df['is_train']\n",
    "    X_train = df_encoded.loc[train_mask, feature_cols]\n",
    "    y_train = df.loc[train_mask, target_col]\n",
    "    \n",
    "    model = XGBRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on all test data (batch)\n",
    "    test_mask = df['is_test']\n",
    "    X_test = df_encoded.loc[test_mask, feature_cols]\n",
    "    df.loc[test_mask, 'pred'] = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics by ID (vectorized where possible)\n",
    "    results = {}\n",
    "    \n",
    "    for uid in df[id_col].unique():\n",
    "        mask = df[id_col] == uid\n",
    "        series_df = df[mask].copy()\n",
    "        \n",
    "        train_vals = series_df[series_df['is_train']][target_col].values\n",
    "        test_vals = series_df[series_df['is_test']][target_col].values\n",
    "        pred_vals = series_df[series_df['is_test']]['pred'].values\n",
    "        \n",
    "        if len(test_vals) > 0 and len(pred_vals) > 0:\n",
    "            min_len = min(len(test_vals), len(pred_vals))\n",
    "            actual = test_vals[:min_len]\n",
    "            pred = pred_vals[:min_len]\n",
    "            \n",
    "            mae = np.mean(np.abs(actual - pred))\n",
    "            rmse = np.sqrt(np.mean((actual - pred) ** 2))\n",
    "            _rmsse = rmsse(train_vals, actual, pred)\n",
    "        else:\n",
    "            mae, rmse, _rmsse = np.nan, np.nan, np.nan\n",
    "        \n",
    "        results[uid] = {\n",
    "            \"XGB\": {\n",
    "                'RMSE': rmse,\n",
    "                'MAE': mae,\n",
    "                'RMSSE': _rmsse,\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bb84a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            XGB\n",
      "RMSE   1.325208\n",
      "MAE    1.027778\n",
      "RMSSE  1.019561\n"
     ]
    }
   ],
   "source": [
    "all_results_ml = forecast_with_ml(\n",
    "     df=df_prepared,\n",
    "     id_col='id',\n",
    "     date_col='date', \n",
    "     target_col='sales',\n",
    "     forecast_horizon=60,\n",
    "     train_ratio=TRAIN_TEST_SPLIT\n",
    ")\n",
    "\n",
    "# View results\n",
    "# Rest of your code remains the same\n",
    "global_results = {}\n",
    "for product, models in all_results_ml.items():\n",
    "    for model_name, metrics in models.items():\n",
    "        if model_name not in global_results:\n",
    "            global_results[model_name] = {'RMSE': [], 'MAE': [], 'RMSSE': []}\n",
    "        for metric_name, value in metrics.items():\n",
    "            global_results[model_name][metric_name].append(float(value))\n",
    "\n",
    "global_averages = {\n",
    "    model_name: {metric: np.mean(values) for metric, values in metrics.items()}\n",
    "    for model_name, metrics in global_results.items()\n",
    "}\n",
    "print(pd.DataFrame(global_averages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "168d873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts import TimeSeries\n",
    "from darts.models import XGBModel\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "\n",
    "\n",
    "def forecast_with_ml_lags(df, id_col='id', date_col='date', target_col='sales', \n",
    "                          forecast_horizon=60, train_ratio=0.8, lags=None):\n",
    "    \"\"\"\n",
    "    Forecast time series using XGBoost via Darts with lag features\n",
    "    Trains a SINGLE model on ALL series together\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    lags : list or int, optional\n",
    "        Lag values to use. If int, uses lags from 1 to that value.\n",
    "        Default: [-1, -7, -14, -28] (good for daily retail data)\n",
    "    \"\"\"\n",
    "    \n",
    "    if lags is None:\n",
    "        lags = [-1, -7, -14, -28]\n",
    "    elif isinstance(lags, int):\n",
    "        lags = [-i for i in range(1, lags + 1)]\n",
    "    \n",
    "    # Prepare data\n",
    "    df = df.copy()\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "    df = df.sort_values([id_col, date_col]).reset_index(drop=True)\n",
    "    \n",
    "    # Sample IDs\n",
    "    np.random.seed(42)\n",
    "    sample_ids = np.random.choice(unique_ids, size=min(500, len(unique_ids)), replace=False)\n",
    "    df_sample = df[df[id_col].isin(sample_ids)]\n",
    "    \n",
    "    # Prepare future covariates\n",
    "    covariate_cols = ['wday', 'month', 'year', 'event_name_1', 'event_type_1', \n",
    "                      'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI']\n",
    "    covariate_cols = [c for c in covariate_cols if c in df_sample.columns]\n",
    "    \n",
    "    # Encode categorical columns\n",
    "    df_encoded = df_sample.copy()\n",
    "    for col in covariate_cols:\n",
    "        if df_encoded[col].dtype == 'object':\n",
    "            df_encoded[col] = pd.Categorical(df_encoded[col]).codes\n",
    "    \n",
    "    # Group by ID and prepare all series\n",
    "    grouped = df_encoded.groupby(id_col)\n",
    "    \n",
    "    all_train_series = []\n",
    "    all_train_cov = []\n",
    "    all_test_data = []\n",
    "    max_lag = abs(min(lags))\n",
    "    \n",
    "    # Prepare all series for batch training\n",
    "    for uid, series_df in grouped:\n",
    "        if len(series_df) < max_lag + forecast_horizon:\n",
    "            continue\n",
    "        \n",
    "        # Create TimeSeries\n",
    "        target_series = TimeSeries.from_dataframe(\n",
    "            series_df, time_col=date_col, value_cols=target_col,\n",
    "            fill_missing_dates=True, freq='D'\n",
    "        )\n",
    "        \n",
    "        future_covariates = None\n",
    "        if covariate_cols:\n",
    "            future_covariates = TimeSeries.from_dataframe(\n",
    "                series_df, time_col=date_col, value_cols=covariate_cols,\n",
    "                fill_missing_dates=True, freq='D'\n",
    "            )\n",
    "        \n",
    "        # Split train/test\n",
    "        split_point = int(len(target_series) * train_ratio)\n",
    "        train_series = target_series[:split_point]\n",
    "        test_series = target_series[split_point:split_point + forecast_horizon]\n",
    "        \n",
    "        if len(test_series) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Collect training data\n",
    "        all_train_series.append(train_series)\n",
    "        \n",
    "        if future_covariates is not None:\n",
    "            train_cov = future_covariates[:split_point]\n",
    "            future_cov = future_covariates[:split_point + forecast_horizon]\n",
    "            all_train_cov.append(train_cov)\n",
    "        \n",
    "        # Store test info for later\n",
    "        all_test_data.append({\n",
    "            'uid': uid,\n",
    "            'train_vals': train_series.values().flatten(),\n",
    "            'test_vals': test_series.values().flatten(),\n",
    "            'test_series': test_series,\n",
    "            'train_series': train_series,  # Need this for prediction\n",
    "            'future_cov': future_cov if future_covariates is not None else None\n",
    "        })\n",
    "    \n",
    "    # Train ONE model on ALL series\n",
    "    model = XGBModel(\n",
    "        lags=lags,\n",
    "        lags_future_covariates=[0] if covariate_cols else None,\n",
    "        output_chunk_length=forecast_horizon,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        series=all_train_series,\n",
    "        future_covariates=all_train_cov if all_train_cov else None\n",
    "    )\n",
    "    \n",
    "    # Predict for all series and calculate metrics\n",
    "    results = {}\n",
    "    \n",
    "    for test_info in all_test_data:\n",
    "        try:\n",
    "            # Predict for this series - need to pass the training series so model can extract lags\n",
    "            prediction = model.predict(\n",
    "                n=len(test_info['test_series']),\n",
    "                series=test_info['train_series'],  # Pass training series, not test\n",
    "                future_covariates=test_info['future_cov']\n",
    "            )\n",
    "            \n",
    "            pred_vals = prediction.values().flatten()\n",
    "            test_vals = test_info['test_vals']\n",
    "            train_vals = test_info['train_vals']\n",
    "            \n",
    "            # Calculate metrics\n",
    "            min_len = min(len(test_vals), len(pred_vals))\n",
    "            actual = test_vals[:min_len]\n",
    "            pred = pred_vals[:min_len]\n",
    "            \n",
    "            mae = np.mean(np.abs(actual - pred))\n",
    "            rmse = np.sqrt(np.mean((actual - pred) ** 2))\n",
    "            _rmsse = rmsse(train_vals, actual, pred)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error predicting ID {test_info['uid']}: {str(e)}\")\n",
    "            mae, rmse, _rmsse = np.nan, np.nan, np.nan\n",
    "        \n",
    "        results[test_info['uid']] = {\n",
    "            \"XGB_Darts\": {\n",
    "                'RMSE': rmse,\n",
    "                'MAE': mae,\n",
    "                'RMSSE': _rmsse,\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f72de77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       XGB_Darts\n",
      "RMSE    1.360555\n",
      "MAE     1.067951\n",
      "RMSSE   1.028694\n"
     ]
    }
   ],
   "source": [
    "all_results_ml_lags = forecast_with_ml_lags(\n",
    "     df=df_prepared,\n",
    "     id_col='id',\n",
    "     date_col='date', \n",
    "     target_col='sales',\n",
    "     forecast_horizon=60,\n",
    "     train_ratio=TRAIN_TEST_SPLIT\n",
    ")\n",
    "\n",
    "# View results\n",
    "# Rest of your code remains the same\n",
    "global_results = {}\n",
    "for product, models in all_results_ml_lags.items():\n",
    "    for model_name, metrics in models.items():\n",
    "        if model_name not in global_results:\n",
    "            global_results[model_name] = {'RMSE': [], 'MAE': [], 'RMSSE': []}\n",
    "        for metric_name, value in metrics.items():\n",
    "            global_results[model_name][metric_name].append(float(value))\n",
    "\n",
    "global_averages = {\n",
    "    model_name: {metric: np.mean(values) for metric, values in metrics.items()}\n",
    "    for model_name, metrics in global_results.items()\n",
    "}\n",
    "print(pd.DataFrame(global_averages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ea70c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Union\n",
    "def forecast_with_ml_lags_price(\n",
    "    df: pd.DataFrame,\n",
    "    id_col: str = \"id\",\n",
    "    date_col: str = \"date\",\n",
    "    target_col: str = \"sales\",\n",
    "    forecast_horizon: int = 60,\n",
    "    train_ratio: float = 0.8,\n",
    "    lags: Optional[Union[List[int], int]] = None,\n",
    "    past_cov_cols: Optional[List[str]] = None,\n",
    "    future_cov_cols: Optional[List[str]] = None,\n",
    "    sample_size: int = 500,\n",
    "    random_state: int = 42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a single XGBoost model (via Darts) on multiple series using lag features.\n",
    "    Returns a DataFrame of per-series metrics (RMSE, MAE, RMSSE).\n",
    "\n",
    "    Simplified & robust: consistent categorical encoding, fixes undefined vars, clearer splits.\n",
    "    \"\"\"\n",
    "\n",
    "    # defaults\n",
    "    if lags is None:\n",
    "        lags = [-1, -7, -14, -28]\n",
    "    elif isinstance(lags, int):\n",
    "        lags = [-i for i in range(1, lags + 1)]\n",
    "\n",
    "    if future_cov_cols is None:\n",
    "        future_cov_cols = [\n",
    "            \"wday\", \"month\", \"year\", \"event_name_1\", \"event_type_1\",\n",
    "            \"event_name_2\", \"event_type_2\", \"snap_CA\", \"snap_TX\", \"snap_WI\",\n",
    "        ]\n",
    "    if past_cov_cols is None:\n",
    "        past_cov_cols = []\n",
    "\n",
    "    # prepare dataframe\n",
    "    df = df.copy()\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "    df = df.sort_values([id_col, date_col]).reset_index(drop=True)\n",
    "\n",
    "    # consistent categorical encoding across the whole dataframe\n",
    "    cov_cols = [c for c in (future_cov_cols + past_cov_cols) if c in df.columns]\n",
    "    for c in cov_cols:\n",
    "        if df[c].dtype == \"object\" or pd.api.types.is_categorical_dtype(df[c]):\n",
    "            df[c] = pd.Categorical(df[c]).codes.astype(float)\n",
    "\n",
    "    # sample ids (stable)\n",
    "    np.random.seed(random_state)\n",
    "    sample_ids = np.random.choice(unique_ids, size=min(sample_size, len(unique_ids)), replace=False)\n",
    "    df_sample = df[df[id_col].isin(sample_ids)]\n",
    "\n",
    "    grouped = df_sample.groupby(id_col)\n",
    "\n",
    "    max_lag = abs(min(lags))\n",
    "    train_series_list = []\n",
    "    train_future_cov_list = []   # future covariates covering the training window\n",
    "    train_past_cov_list = []     # past covariates covering the training window\n",
    "    tests = []                   # list of dicts with test info per series\n",
    "\n",
    "    for uid, g in grouped:\n",
    "        g = g.sort_values(date_col)\n",
    "        if len(g) < max_lag + 2 + forecast_horizon:  # require a little extra history\n",
    "            continue\n",
    "\n",
    "        # build TimeSeries objects\n",
    "        target_ts = TimeSeries.from_dataframe(g, time_col=date_col, value_cols=target_col, fill_missing_dates=True, freq=\"D\")\n",
    "\n",
    "        fut_cov_ts = None\n",
    "        if any(col in g.columns for col in future_cov_cols):\n",
    "            present_fut = [c for c in future_cov_cols if c in g.columns]\n",
    "            fut_cov_ts = TimeSeries.from_dataframe(g, time_col=date_col, value_cols=present_fut, fill_missing_dates=True, freq=\"D\")\n",
    "\n",
    "        past_cov_ts = None\n",
    "        if any(col in g.columns for col in past_cov_cols):\n",
    "            present_past = [c for c in past_cov_cols if c in g.columns]\n",
    "            past_cov_ts = TimeSeries.from_dataframe(g, time_col=date_col, value_cols=present_past, fill_missing_dates=True, freq=\"D\")\n",
    "\n",
    "        # split: keep original ratio but ensure we have forecast_horizon in the test slice\n",
    "        split_point = int(len(target_ts) * train_ratio)\n",
    "        # ensure there is room for forecast horizon\n",
    "        if split_point + forecast_horizon > len(target_ts):\n",
    "            split_point = len(target_ts) - forecast_horizon\n",
    "        if split_point <= max_lag:\n",
    "            continue\n",
    "\n",
    "        train_ts = target_ts[:split_point]\n",
    "        test_ts = target_ts[split_point: split_point + forecast_horizon]\n",
    "        if len(test_ts) == 0:\n",
    "            continue\n",
    "\n",
    "        train_series_list.append(train_ts)\n",
    "        # training covariates must align with the training window\n",
    "        train_future_cov_list.append(fut_cov_ts[:split_point] if fut_cov_ts is not None else None)\n",
    "        train_past_cov_list.append(past_cov_ts[:split_point] if past_cov_ts is not None else None)\n",
    "\n",
    "        # Store test info\n",
    "        full_future_for_pred = fut_cov_ts[:split_point + len(test_ts)] if fut_cov_ts is not None else None\n",
    "        full_past_for_pred = past_cov_ts[:split_point] if past_cov_ts is not None else None\n",
    "\n",
    "        tests.append({\n",
    "            \"uid\": uid,\n",
    "            \"train_series\": train_ts,\n",
    "            \"train_vals\": train_ts.values().flatten(),\n",
    "            \"test_series\": test_ts,\n",
    "            \"test_vals\": test_ts.values().flatten(),\n",
    "            \"future_cov_full\": full_future_for_pred,\n",
    "            \"past_cov_full\": full_past_for_pred,   # <-- NEW\n",
    "        })\n",
    "\n",
    "    if len(train_series_list) == 0:\n",
    "        raise ValueError(\"No series qualified for training (increase sample_size or reduce forecast_horizon).\")\n",
    "\n",
    "    # decide which covariates to pass to fit()\n",
    "    future_cov_for_fit = train_future_cov_list if any(x is not None for x in train_future_cov_list) else None\n",
    "    past_cov_for_fit = train_past_cov_list if any(x is not None for x in train_past_cov_list) else None\n",
    "\n",
    "    print(\"fit\")\n",
    "    # create and fit the model\n",
    "    model = XGBModel(\n",
    "        lags=lags,\n",
    "        lags_future_covariates=[0] if future_cov_for_fit is not None else None, \n",
    "        lags_past_covariates=[-1],\n",
    "        output_chunk_length=forecast_horizon,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    model.fit(series=train_series_list,\n",
    "              future_covariates=future_cov_for_fit,\n",
    "              past_covariates=past_cov_for_fit)\n",
    "\n",
    "    # predict & evaluate\n",
    "    records = {}\n",
    "    for t in tests:\n",
    "        try:\n",
    "            pred_ts = model.predict(\n",
    "                n=len(t[\"test_series\"]),\n",
    "                series=t[\"train_series\"],\n",
    "                future_covariates=t[\"future_cov_full\"],\n",
    "                past_covariates=t[\"past_cov_full\"],   # <-- NEW\n",
    "            )\n",
    "            pred_vals = pred_ts.values().flatten()\n",
    "            actual = t[\"test_vals\"]\n",
    "            train_vals = t[\"train_vals\"]\n",
    "\n",
    "            min_len = min(len(actual), len(pred_vals))\n",
    "            actual = actual[:min_len]\n",
    "            pred_vals = pred_vals[:min_len]\n",
    "\n",
    "            mae = float(np.mean(np.abs(actual - pred_vals)))\n",
    "            rmse = float(np.sqrt(np.mean((actual - pred_vals) ** 2)))\n",
    "            rmsse_val = rmsse(train_vals, actual, pred_vals)\n",
    "        except Exception as e:\n",
    "            mae = rmse = rmsse_val = np.nan\n",
    "\n",
    "        uid = t[\"uid\"]\n",
    "        records[uid] = {\n",
    "            \"XGB_Darts\": {\n",
    "                'RMSE': rmse,\n",
    "                'MAE': mae,\n",
    "                'RMSSE': rmsse_val,\n",
    "            }\n",
    "        }\n",
    "\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "211fcd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit\n",
      "       XGB_Darts\n",
      "RMSE    1.360145\n",
      "MAE     1.057615\n",
      "RMSSE   1.034130\n"
     ]
    }
   ],
   "source": [
    "all_results_ml_lags_price = forecast_with_ml_lags_price(\n",
    "    df_prepared, \n",
    "    sample_size=500,\n",
    "    train_ratio=TRAIN_TEST_SPLIT,\n",
    "    past_cov_cols=['sell_price'],  # Won't have these in future\n",
    "    future_cov_cols=['wday', 'month', 'year', 'event_name_1', 'event_type_1', \n",
    "                      'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI']  # Will have these\n",
    ")\n",
    "\n",
    "# View results\n",
    "# Rest of your code remains the same\n",
    "global_results = {}\n",
    "for product, models in all_results_ml_lags_price.items():\n",
    "    for model_name, metrics in models.items():\n",
    "        if model_name not in global_results:\n",
    "            global_results[model_name] = {'RMSE': [], 'MAE': [], 'RMSSE': []}\n",
    "        for metric_name, value in metrics.items():\n",
    "            global_results[model_name][metric_name].append(float(value))\n",
    "\n",
    "global_averages = {\n",
    "    model_name: {metric: np.mean(values) for metric, values in metrics.items()}\n",
    "    for model_name, metrics in global_results.items()\n",
    "}\n",
    "print(pd.DataFrame(global_averages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbad47f1",
   "metadata": {},
   "source": [
    "### Foundational Model Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e6afef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timesfm\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def initialize_model():\n",
    "    \"\"\"Initialize TimesFM model (call once)\"\"\"\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "    \n",
    "    model = timesfm.TimesFM_2p5_200M_torch.from_pretrained(\"google/timesfm-2.5-200m-pytorch\")\n",
    "    \n",
    "    model.compile(\n",
    "        timesfm.ForecastConfig(\n",
    "            max_context=1024,\n",
    "            max_horizon=256,\n",
    "            normalize_inputs=True,\n",
    "            use_continuous_quantile_head=True,\n",
    "            force_flip_invariance=True,\n",
    "            infer_is_positive=True,\n",
    "            fix_quantile_crossing=True,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "    \n",
    "# ============================================\n",
    "# Batch Version (More Efficient)\n",
    "# ============================================\n",
    "def forecast_with_timesfm_batch(df, id_col='id', date_col='date', target_col='sales', \n",
    "                                forecast_horizon=60, train_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Batch version for faster processing of multiple time series\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Load TimesFM model\n",
    "    print(\"Loading TimesFM model...\")\n",
    "    model = initialize_model()\n",
    "    \n",
    "    # 2. Prepare data\n",
    "    df = df.copy()\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "    df = df.sort_values([id_col, date_col])\n",
    "        \n",
    "    # 3. Collect all series\n",
    "    all_train = []\n",
    "    all_test = []\n",
    "    valid_ids = []\n",
    "    \n",
    "    np.random.seed(42)  # or any integer you prefer\n",
    "    sample_ids = np.random.choice(unique_ids, size=min(500, len(unique_ids)), replace=False)\n",
    "    grouped = df[df[id_col].isin(sample_ids)].groupby(id_col)[target_col].apply(lambda x: x.values)\n",
    "    \n",
    "    for uid, series_data in grouped.items():\n",
    "        split = int(len(series_data) * train_ratio)\n",
    "        train = series_data[:split]\n",
    "        test = series_data[split:split + forecast_horizon]\n",
    "        \n",
    "        all_train.append(train)\n",
    "        all_test.append(test)\n",
    "        valid_ids.append(uid)\n",
    "    \n",
    "    # 4. Batch forecast (all at once!)\n",
    "    print(f\"Forecasting {len(valid_ids)} series in one batch...\")\n",
    "    point_forecast, quantile_forecast = model.forecast(\n",
    "        horizon=forecast_horizon,\n",
    "        inputs=all_train,  # All time series at once\n",
    "    )\n",
    "    \n",
    "    # 5. Process results\n",
    "    results = {}\n",
    "    for i, uid in enumerate(tqdm(valid_ids)):\n",
    "        predictions = point_forecast[i]\n",
    "        test = all_test[i]\n",
    "        train = all_train[i]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        if len(test) > 0:\n",
    "            min_len = min(len(test), len(predictions))\n",
    "            actual = test[:min_len]\n",
    "            pred = predictions[:min_len]\n",
    "            train = all_train[i]\n",
    "            \n",
    "            mae = np.mean(np.abs(actual - pred))\n",
    "            rmse = np.sqrt(np.mean((actual - pred) ** 2))\n",
    "            _rmsse = rmsse(train, test, pred)\n",
    "        else:\n",
    "            mae, rmse, _rmsse = None, None, None\n",
    "        \n",
    "        results[uid] = {\"FM\": {\n",
    "            'RMSE': rmse,  \n",
    "            'MAE': mae,   \n",
    "            'RMSSE': _rmsse,\n",
    "        }}\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79cd020f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TimesFM model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "686146bfac6f4cb88484961186a107c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/475 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded.\n",
      "Forecasting 500 series in one batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 22113.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             FM\n",
      "RMSE   1.276774\n",
      "MAE    0.833277\n",
      "RMSSE  0.979278\n"
     ]
    }
   ],
   "source": [
    "all_results_fm = forecast_with_timesfm_batch(\n",
    "     df=df_prepared,\n",
    "     id_col='id',\n",
    "     date_col='date', \n",
    "     target_col='sales',\n",
    "     forecast_horizon=60,\n",
    "     train_ratio=TRAIN_TEST_SPLIT\n",
    ")\n",
    "\n",
    "# View results\n",
    "# Rest of your code remains the same\n",
    "global_results = {}\n",
    "for product, models in all_results_fm.items():\n",
    "    for model_name, metrics in models.items():\n",
    "        if model_name not in global_results:\n",
    "            global_results[model_name] = {'RMSE': [], 'MAE': [], 'RMSSE': []}\n",
    "        for metric_name, value in metrics.items():\n",
    "            global_results[model_name][metric_name].append(float(value))\n",
    "\n",
    "global_averages = {\n",
    "    model_name: {metric: np.mean(values) for metric, values in metrics.items()}\n",
    "    for model_name, metrics in global_results.items()\n",
    "}\n",
    "print(pd.DataFrame(global_averages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5412ebad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m5-forecasting-competition-o6izWvG--py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
